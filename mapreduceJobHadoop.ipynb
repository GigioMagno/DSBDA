{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84a391-f191-476d-b1d4-a2a84089f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even if I run the command \"start-all.sh\" I will obtain errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bb06b22-553a-4850-8bcf-48b6e6cc3074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/06/24 14:00:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/24 14:00:52 WARN hdfs.DataStreamer: DataStreamer Exception\n",
      "org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /listings_details/part-00000-94f21158-d2e6-43bf-bb69-e18e8aedb9d2-c000.csv._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.\n",
      "\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1832)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:265)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2591)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:880)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:517)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:994)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:922)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2833)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1540)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1486)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1385)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)\n",
      "\tat com.sun.proxy.$Proxy10.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:448)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy11.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1846)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1645)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:710)\n",
      "put: File /listings_details/part-00000-94f21158-d2e6-43bf-bb69-e18e8aedb9d2-c000.csv._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.\n",
      "24/06/24 14:00:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/24 14:00:53 WARN hdfs.DataStreamer: DataStreamer Exception\n",
      "org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /listings_details/part-00000-94f21158-d2e6-43bf-bb69-e18e8aedb9d2-c000.csv._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.\n",
      "\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1832)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:265)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2591)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:880)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:517)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:994)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:922)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2833)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1540)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1486)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1385)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)\n",
      "\tat com.sun.proxy.$Proxy10.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:448)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy11.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1846)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1645)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:710)\n",
      "put: File /listings_details/part-00000-94f21158-d2e6-43bf-bb69-e18e8aedb9d2-c000.csv._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.\n"
     ]
    }
   ],
   "source": [
    "#Load the listings on hdfs -> it says that no namenode is running\n",
    "!hadoop fs -put -f -p ../listings_details_select/part-00000-94f21158-d2e6-43bf-bb69-e18e8aedb9d2-c000.csv hdfs://localhost:54310/listings_details/\n",
    "!hadoop fs -put -f -p ../listings_details_select/part-00000-94f21158-d2e6-43bf-bb69-e18e8aedb9d2-c000.csv /listings_details/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09c09ee3-77cd-427f-a0ce-4942626b8f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/06/24 14:06:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "rm: `/final_project/': No such file or directory\n",
      "24/06/24 14:06:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/24 14:06:06 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "24/06/24 14:06:06 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "24/06/24 14:06:06 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "24/06/24 14:06:06 INFO mapred.FileInputFormat: Total input files to process : 2\n",
      "24/06/24 14:06:06 INFO mapreduce.JobSubmitter: Cleaning up the staging area file:/app/hadoop/tmp/mapred/staging/ubuntu469222044/.staging/job_local469222044_0001\n",
      "24/06/24 14:06:06 ERROR streaming.StreamJob: Error Launching job : Not a file: hdfs://localhost:54310/user/ubuntu/ciao/reviews_details_cleaned.csv\n",
      "Streaming Command Failed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = './mapper.py'\n",
    "reducer = './reducer.py'\n",
    "listings_details = '/user/ubuntu/ciao/listings_details/'\n",
    "reviews_details = '/user/ubuntu/ciao/reviews_details/'\n",
    "joined_dataset = '/user/ubuntu/ciao/join/'\n",
    "streaming_jar = '/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.10.0.jar'\n",
    "\n",
    "# Delete any old join MapReduce job output, if necessary\n",
    "!hadoop fs -rm -r /final_project/ > /dev/null\n",
    "\n",
    "# Execute the actual join MapReduce job\n",
    "!hadoop jar $streaming_jar -files $mapper,$reducer -mapper $mapper -reducer $reducer -input $listings_details_select -input $reviews_details -output $joined_dataset\n",
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324b4cf4-6eb9-48dc-a83a-cb7bfbd2f087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/06/24 14:10:56 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/24 14:10:56 WARN hdfs.DataStreamer: DataStreamer Exception\n",
      "org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/ubuntu/ciao/reviews_details.csv._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.\n",
      "\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1832)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:265)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2591)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:880)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:517)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:507)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1034)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:994)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:922)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2833)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1540)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1486)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1385)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)\n",
      "\tat com.sun.proxy.$Proxy10.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:448)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy11.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1846)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1645)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:710)\n",
      "put: File /user/ubuntu/ciao/reviews_details.csv._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -put -f -p ../listings_details_select/part-00000-94f21158-d2e6-43bf-bb69-e18e8aedb9d2-c000.csv /user/ubuntu/ciao/reviews_details.csv\n",
    "#I tried several ways, but it continues to not work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df2c33-911f-40ff-9963-545eefcf2dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
