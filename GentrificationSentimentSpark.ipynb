{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb4054e-3643-4e4b-b62f-9f0cb3bcfbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, row_number, regexp_replace, sum, when, count, round as sparkrnd, max as sparkmax, min as sparkmin, year, avg as sparkavg, stddev as sparkstd\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af9e8bf-ac8d-4ca8-93aa-b44fcf3441b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/25 09:11:10 WARN Utils: Your hostname, dsbda-vm resolves to a loopback address: 127.0.1.1; using 192.168.64.2 instead (on interface enp0s1)\n",
      "24/06/25 09:11:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/25 09:11:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ebbe483-25d4-4eff-8ed6-c7b3c59676fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing tables for spark join\n",
    "\n",
    "file_path_listings = \"/home/ubuntu/DATASET/listings_details.csv\"\n",
    "file_path_reviews = \"/home/ubuntu/DATASET/reviews_details.csv\"\n",
    "\n",
    "\n",
    "df_listings = spark.read.csv(file_path_listings, header=True, inferSchema=True, sep=\",\", quote= '\"', escape= '\"', multiLine=True, mode=\"DROPMALFORMED\")\n",
    "df_cleaned_listings = df_listings.withColumn(\"price\", regexp_replace(col(\"price\"), r\"[\\$,]\", \"\").cast(\"double\"))\n",
    "for col_name in df_cleaned_listings.columns:\n",
    "        df_cleaned_listings = df_cleaned_listings.withColumn(col_name, regexp_replace(col(col_name), \"[^a-zA-Z0-9 .]\", \"\"))\n",
    "df_filtered_listings = df_cleaned_listings.filter( col(\"id\").cast(IntegerType()).isNotNull()\n",
    ")\n",
    "\n",
    "#df_filtered_listings.printSchema()\n",
    "df_filtered_listings = df_filtered_listings.select(\"id\", \"name\", \"host_name\", \"neighbourhood_cleansed\", \"latitude\", \"longitude\", \n",
    "                                 \"property_type\", \"room_type\", \"price\", \"review_scores_rating\", \"review_scores_accuracy\", \n",
    "                                 \"review_scores_cleanliness\", \"review_scores_checkin\", \"review_scores_communication\", \n",
    "                                 \"review_scores_location\", \"review_scores_value\", \"reviews_per_month\")\n",
    "\n",
    "\n",
    "\n",
    "schema_rev = StructType([\n",
    "    StructField(\"listing_id\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"reviewer_id\", StringType(), True),\n",
    "    StructField(\"reviewer_name\", StringType(), True),\n",
    "    StructField(\"comments\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "df_reviews = spark.read.csv(file_path_reviews, header=True, schema=schema_rev, sep=\",\", quote= '\"', escape= '\"', multiLine=True, mode=\"DROPMALFORMED\")\n",
    "for col_name in df_reviews.columns:\n",
    "        if col_name == \"date\":\n",
    "            df_reviews= df_reviews.withColumn(col_name, regexp_replace(col(col_name), \"[^0-9 -]\", \"\"))\n",
    "        else:\n",
    "            df_reviews = df_reviews.withColumn(col_name, regexp_replace(col(col_name), \"[^a-zA-Z0-9 .]\", \"\"))\n",
    "df_reviews = df_reviews.filter(col(\"listing_id\").cast(\"int\").isNotNull())\n",
    "\n",
    "#df_reviews.printSchema()\n",
    "\n",
    "#I have to limit the output because on spark it's costly!\n",
    "#df_reviews.show(20)\n",
    "\n",
    "#df_reviews.select(\"listing_id\", \"date\", \"comments\").show()\n",
    "df_reviews = df_reviews.select(\"listing_id\", \"date\", \"comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "049bb1f2-f089-4c9b-b7d8-49aa8620136a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Listing_ID: string (nullable = true)\n",
      " |-- Listing_name: string (nullable = true)\n",
      " |-- Hostname: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- PropertyType: string (nullable = true)\n",
      " |-- RoomType: string (nullable = true)\n",
      " |-- Price: string (nullable = true)\n",
      " |-- ReviewScoresRating: string (nullable = true)\n",
      " |-- ReviewScoresAccuracy: string (nullable = true)\n",
      " |-- ReviewScoresCleanliness: string (nullable = true)\n",
      " |-- ReviewScoresCheckin: string (nullable = true)\n",
      " |-- ReviewScoresCommunication: string (nullable = true)\n",
      " |-- ReviewScoresLocation: string (nullable = true)\n",
      " |-- ReviewScoresValue: string (nullable = true)\n",
      " |-- ReviewPerMonth: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Comment: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark dataframe length: 431311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "remapped_schema = {\"id\":\"Listing_ID\", \"name\":\"Listing_name\", \"host_name\":\"Hostname\", \"neighbourhood_cleansed\":\"Neighborhood\",\n",
    "                   \"latitude\":\"Latitude\", \"longitude\":\"Longitude\", \"property_type\":\"PropertyType\", \"room_type\":\"RoomType\",\n",
    "                   \"price\":\"Price\", \"review_scores_rating\":\"ReviewScoresRating\", \"review_scores_accuracy\":\"ReviewScoresAccuracy\",\n",
    "                   \"review_scores_cleanliness\":\"ReviewScoresCleanliness\", \"review_scores_checkin\":\"ReviewScoresCheckin\",\n",
    "                   \"review_scores_communication\":\"ReviewScoresCommunication\", \"review_scores_location\":\"ReviewScoresLocation\",\n",
    "                   \"review_scores_value\":\"ReviewScoresValue\", \"reviews_per_month\":\"ReviewPerMonth\", \"date\":\"Date\", \"comments\":\"Comment\"}\n",
    "\n",
    "joined_df = df_filtered_listings.join(df_reviews, df_filtered_listings.id == df_reviews.listing_id, 'inner').drop(df_reviews.listing_id)\n",
    "\n",
    "for old_name, new_col in remapped_schema.items():\n",
    "    joined_df = joined_df.withColumnRenamed(old_name, new_col)\n",
    "\n",
    "\n",
    "joined_df = joined_df.filter(col(\"Listing_ID\").isNotNull()).filter(col(\"Comment\").isNotNull())\n",
    "joined_df.printSchema()\n",
    "\n",
    "num_rows = joined_df.count()\n",
    "\n",
    "# Stampa il numero di righe\n",
    "print(f\"spark dataframe length: {num_rows}\")\n",
    "#joined_df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c8e3598-ef7e-4822-b11c-2dd34d736f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType, StringType\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5123f00-edd4-4ccf-9b08-63534fc9cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "346c757d-9065-47dd-8595-df083b57c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark dataframe length: 431311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Score computation of the reviews\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentiment_udf = udf(analyze_sentiment, FloatType()) #create a function\n",
    "sdf_with_score = joined_df.withColumn(\"SentimentScore\", sentiment_udf(joined_df[\"Comment\"]))\n",
    "sdf_with_score = sdf_with_score.dropna(subset=[\"SentimentScore\"])\n",
    "num_rows = sdf_with_score.count()\n",
    "\n",
    "# Stampa il numero di righe\n",
    "print(f\"spark dataframe length: {num_rows}\")\n",
    "#Limit for the print since I'm working with spark df\n",
    "#sdf_with_score.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66f138d0-6f9f-4afa-a8d3-9cd92237e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-1, -0.75, -0.25, 0.25, 0.75, 1]\n",
    "labels = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa164ff9-96be-42c8-a1b7-fd78ea3c4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_with_score = sdf_with_score.withColumn(\n",
    "    \"BinSentimentScore\",\n",
    "    when(col(\"SentimentScore\") <= bins[1], labels[0])\n",
    "    .when((col(\"SentimentScore\") > bins[1]) & (col(\"SentimentScore\") <= bins[2]), labels[1])\n",
    "    .when((col(\"SentimentScore\") > bins[2]) & (col(\"SentimentScore\") <= bins[3]), labels[2])\n",
    "    .when((col(\"SentimentScore\") > bins[3]) & (col(\"SentimentScore\") <= bins[4]), labels[3])\n",
    "    .otherwise(labels[4])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93327d85-72d1-434f-844e-a9b287a33c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Listing_ID: string (nullable = true)\n",
      " |-- Listing_name: string (nullable = true)\n",
      " |-- Hostname: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- PropertyType: string (nullable = true)\n",
      " |-- RoomType: string (nullable = true)\n",
      " |-- Price: string (nullable = true)\n",
      " |-- ReviewScoresRating: string (nullable = true)\n",
      " |-- ReviewScoresAccuracy: string (nullable = true)\n",
      " |-- ReviewScoresCleanliness: string (nullable = true)\n",
      " |-- ReviewScoresCheckin: string (nullable = true)\n",
      " |-- ReviewScoresCommunication: string (nullable = true)\n",
      " |-- ReviewScoresLocation: string (nullable = true)\n",
      " |-- ReviewScoresValue: string (nullable = true)\n",
      " |-- ReviewPerMonth: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Comment: string (nullable = true)\n",
      " |-- SentimentScore: float (nullable = true)\n",
      " |-- BinSentimentScore: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_with_score.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31d449dd-c346-45d0-a700-44b2536b9671",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_with_score = sdf_with_score.dropna(subset=[\"Comment\", \"Date\", \"BinSentimentScore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae1495c3-965f-47d7-8fde-acf692d364cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------+------------+-----------------+----------------+------------+--------------+-----+------------------+--------------------+-----------------------+-------------------+-------------------------+--------------------+-----------------+--------------+----------+--------------------+--------------+-----------------+\n",
      "|Listing_ID|        Listing_name|Hostname|Neighborhood|         Latitude|       Longitude|PropertyType|      RoomType|Price|ReviewScoresRating|ReviewScoresAccuracy|ReviewScoresCleanliness|ReviewScoresCheckin|ReviewScoresCommunication|ReviewScoresLocation|ReviewScoresValue|ReviewPerMonth|      Date|             Comment|SentimentScore|BinSentimentScore|\n",
      "+----------+--------------------+--------+------------+-----------------+----------------+------------+--------------+-----+------------------+--------------------+-----------------------+-------------------+-------------------------+--------------------+-----------------+--------------+----------+--------------------+--------------+-----------------+\n",
      "|    588116|Sweet Amsterdam a...| Fanneke|     OudOost|52.35045235319899|4.91614014872195|   Apartment|Entire homeapt| 90.0|                96|                  10|                     10|                 10|                       10|                   9|               10|          0.57|2013-08-10|I had a great sta...|        0.9926|                5|\n",
      "|    588116|Sweet Amsterdam a...| Fanneke|     OudOost|52.35045235319899|4.91614014872195|   Apartment|Entire homeapt| 90.0|                96|                  10|                     10|                 10|                       10|                   9|               10|          0.57|2013-08-12|She has wonderful...|        0.9184|                5|\n",
      "|    588116|Sweet Amsterdam a...| Fanneke|     OudOost|52.35045235319899|4.91614014872195|   Apartment|Entire homeapt| 90.0|                96|                  10|                     10|                 10|                       10|                   9|               10|          0.57|2013-10-22|This was my first...|        0.9889|                5|\n",
      "|    588116|Sweet Amsterdam a...| Fanneke|     OudOost|52.35045235319899|4.91614014872195|   Apartment|Entire homeapt| 90.0|                96|                  10|                     10|                 10|                       10|                   9|               10|          0.57|2014-09-16|All the words I c...|        0.9771|                5|\n",
      "|    588116|Sweet Amsterdam a...| Fanneke|     OudOost|52.35045235319899|4.91614014872195|   Apartment|Entire homeapt| 90.0|                96|                  10|                     10|                 10|                       10|                   9|               10|          0.57|2014-10-21|A real great slee...|        0.9628|                5|\n",
      "|    588116|Sweet Amsterdam a...| Fanneke|     OudOost|52.35045235319899|4.91614014872195|   Apartment|Entire homeapt| 90.0|                96|                  10|                     10|                 10|                       10|                   9|               10|          0.57|2015-01-02|Even we could not...|         0.945|                5|\n",
      "|    588116|Sweet Amsterdam a...| Fanneke|     OudOost|52.35045235319899|4.91614014872195|   Apartment|Entire homeapt| 90.0|                96|                  10|                     10|                 10|                       10|                   9|               10|          0.57|2015-01-05|Fanneke was a gre...|        0.9754|                5|\n",
      "|    588116|Sweet Amsterdam a...| Fanneke|     OudOost|52.35045235319899|4.91614014872195|   Apartment|Entire homeapt| 90.0|                96|                  10|                     10|                 10|                       10|                   9|               10|          0.57|2015-02-24|Nous avons pass u...|         0.836|                5|\n",
      "|    588116|Sweet Amsterdam a...| Fanneke|     OudOost|52.35045235319899|4.91614014872195|   Apartment|Entire homeapt| 90.0|                96|                  10|                     10|                 10|                       10|                   9|               10|          0.57|2015-03-17|Lappartamento di ...|        0.4215|                4|\n",
      "|    588116|Sweet Amsterdam a...| Fanneke|     OudOost|52.35045235319899|4.91614014872195|   Apartment|Entire homeapt| 90.0|                96|                  10|                     10|                 10|                       10|                   9|               10|          0.57|2015-04-07|Fannekes home is ...|        0.9662|                5|\n",
      "+----------+--------------------+--------+------------+-----------------+----------------+------------+--------------+-----+------------------+--------------------+-----------------------+-------------------+-------------------------+--------------------+-----------------+--------------+----------+--------------------+--------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sdf_with_score.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31baa8e5-85c5-4e37-aa76-c4996c616f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_with_year = sdf_with_score.withColumn(\"Year\", year(sdf_with_score[\"date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a126afe-762a-4132-beac-4e4b94ad34eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Listing_ID='588116', Listing_name='Sweet Amsterdam ap. with garden...', Hostname='Fanneke', Neighborhood='OudOost', Latitude='52.35045235319899', Longitude='4.91614014872195', PropertyType='Apartment', RoomType='Entire homeapt', Price='90.0', ReviewScoresRating='96', ReviewScoresAccuracy='10', ReviewScoresCleanliness='10', ReviewScoresCheckin='10', ReviewScoresCommunication='10', ReviewScoresLocation='9', ReviewScoresValue='10', ReviewPerMonth='0.57', Date='2013-08-10', Comment='I had a great stay in Fannekes appartment. Its very well located  in a quiet street and next to a canal  and you kind of get an insight in a normalauthentic neighbourhood without all the touriststuff but youre very close to everywhere by bike. The place itself is spacious perfect for 2 people lovely decorated you got everything you need and on top of that a beautiful garden and a cute little cat. I felt very comfortable there from the day I arrived. I met Fanneke just for half an hour because we both were in a hurry but she was very friendly openminded uncomplicated and helpful with Amsterdam tipps. I can recommend a stay in her appartment to anyone.', SentimentScore=0.9926000237464905, BinSentimentScore=5, Year=2013)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_with_year.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aea94bc6-6510-431c-b144-eddae54ffce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, year, when, lit\n",
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "733deb9b-dc9f-40c3-a192-673d36bac198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mannwhitneyu_test(before_scores, after_scores):\n",
    "    stat, p_val = mannwhitneyu(before_scores, after_scores, alternative='two-sided')\n",
    "    return float(p_val)\n",
    "\n",
    "def analyze_difference(before_scores, after_scores, datetime1, datetime2, year, alpha=0.05):\n",
    "    len_before = len(before_scores)\n",
    "    len_after = len(after_scores)\n",
    "    \n",
    "    if len_before > 0 and len_after > 0:\n",
    "        stat, p_val = mannwhitneyu(before_scores, after_scores, alternative='two-sided')\n",
    "        \n",
    "        print(f\"Comparison: {datetime1} vs {datetime2}\")\n",
    "        print(f\"P-value: {p_val}\")\n",
    "        \n",
    "        if p_val < alpha:\n",
    "            print(\"Significative difference between the sentiment scores before and after (Reject the null hypothesis).\")\n",
    "        else:\n",
    "            print(\"Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d03e3bb-2d7d-4af3-9b09-a191e1f27de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: 2010 first semester vs 2011 first semester\n",
      "P-value: 0.875\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n",
      "Comparison: 2010 second semester vs 2011 second semester\n",
      "P-value: 0.3176287929810796\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n",
      "Comparison: 2010 first semester vs 2010 second semester\n",
      "P-value: 0.7450173057662387\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: 2011 first semester vs 2012 first semester\n",
      "P-value: 0.3176287929810796\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n",
      "Comparison: 2011 second semester vs 2012 second semester\n",
      "P-value: 0.759175444693613\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n",
      "Comparison: 2011 first semester vs 2011 second semester\n",
      "P-value: 0.961419656926375\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: 2012 first semester vs 2013 first semester\n",
      "P-value: 0.759175444693613\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n",
      "Comparison: 2012 second semester vs 2013 second semester\n",
      "P-value: 0.6354308490354297\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n",
      "Comparison: 2012 first semester vs 2012 second semester\n",
      "P-value: 0.9166001150990198\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: 2013 first semester vs 2014 first semester\n",
      "P-value: 0.6354308490354297\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n",
      "Comparison: 2013 second semester vs 2014 second semester\n",
      "P-value: 2.044540868821777e-06\n",
      "Significative difference between the sentiment scores before and after (Reject the null hypothesis).\n",
      "Comparison: 2013 first semester vs 2013 second semester\n",
      "P-value: 0.3152465101101586\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: 2014 first semester vs 2015 first semester\n",
      "P-value: 2.044540868821777e-06\n",
      "Significative difference between the sentiment scores before and after (Reject the null hypothesis).\n",
      "Comparison: 2014 second semester vs 2015 second semester\n",
      "P-value: 0.0004467794465107559\n",
      "Significative difference between the sentiment scores before and after (Reject the null hypothesis).\n",
      "Comparison: 2014 first semester vs 2014 second semester\n",
      "P-value: 1.2260366170514692e-15\n",
      "Significative difference between the sentiment scores before and after (Reject the null hypothesis).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: 2015 first semester vs 2016 first semester\n",
      "P-value: 0.0004467794465107559\n",
      "Significative difference between the sentiment scores before and after (Reject the null hypothesis).\n",
      "Comparison: 2015 second semester vs 2016 second semester\n",
      "P-value: 8.411176590343428e-12\n",
      "Significative difference between the sentiment scores before and after (Reject the null hypothesis).\n",
      "Comparison: 2015 first semester vs 2015 second semester\n",
      "P-value: 0.58776804427465\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: 2016 first semester vs 2017 first semester\n",
      "P-value: 8.411176590343428e-12\n",
      "Significative difference between the sentiment scores before and after (Reject the null hypothesis).\n",
      "Comparison: 2016 second semester vs 2017 second semester\n",
      "P-value: 0.3125231974366046\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n",
      "Comparison: 2016 first semester vs 2016 second semester\n",
      "P-value: 2.420560929498966e-55\n",
      "Significative difference between the sentiment scores before and after (Reject the null hypothesis).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 120:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: 2017 first semester vs 2018 first semester\n",
      "P-value: 0.3125231974366046\n",
      "Non-Significative difference between the sentiment scores before and after (Accept the null hypothesis).\n",
      "Comparison: 2017 second semester vs 2018 second semester\n",
      "P-value: 6.707857903983934e-25\n",
      "Significative difference between the sentiment scores before and after (Reject the null hypothesis).\n",
      "Comparison: 2017 first semester vs 2017 second semester\n",
      "P-value: 2.9185595992502613e-16\n",
      "Significative difference between the sentiment scores before and after (Reject the null hypothesis).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "inner = [\"CentrumWest\", \"CentrumOost\", \"Westerpark\", \"De Baarsjes  OudWest\", \n",
    "         \"Oostelijk Havengebied  Indische Buurt\", \"OudOost\", \n",
    "         \"De Pijp  Rivierenbuurt\"]\n",
    "\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "for year_val in range(2010, 2018):\n",
    "\n",
    "    date_str_prev = f\"{year_val}-06-01\"\n",
    "    date_str_next = f\"{year_val+1}-06-01\"\n",
    "\n",
    "    date_prev = pd.to_datetime(date_str_prev)\n",
    "    date_next = pd.to_datetime(date_str_next)\n",
    "\n",
    "    next_year = year_val+1\n",
    "\n",
    "    df_filtered = sdf_with_year.filter(~col(\"Neighborhood\").isin(inner))\n",
    "    df_out_center_prev = df_filtered.filter(col(\"Year\") == year_val)\n",
    "    df_out_center_next = df_filtered.filter(col(\"Year\") == year_val + 1)\n",
    "\n",
    "    sentiment_scores_outer_before_prev = df_out_center_prev.filter(col(\"Date\") < lit(date_str_prev)).select(\"SentimentScore\")\n",
    "    sentiment_scores_outer_after_prev = df_out_center_prev.filter(col(\"Date\") >= lit(date_str_prev)).select(\"SentimentScore\")\n",
    "    sentiment_scores_outer_before_next = df_out_center_next.filter(col(\"Date\") < lit(date_str_next)).select(\"SentimentScore\")\n",
    "    sentiment_scores_outer_after_next = df_out_center_next.filter(col(\"Date\") >= lit(date_str_next)).select(\"SentimentScore\")\n",
    "\n",
    "    #Since on spark works on spark dataframes I tried to use the mann-whitney U test, but it wasn't available :c -> sorry :C, but the function was not available in DataFrameStatFunctions\n",
    "    before_prev_list = [row.SentimentScore for row in sentiment_scores_outer_before_prev.collect()]\n",
    "    after_prev_list = [row.SentimentScore for row in sentiment_scores_outer_after_prev.collect()]\n",
    "    before_next_list = [row.SentimentScore for row in sentiment_scores_outer_before_next.collect()]\n",
    "    after_next_list = [row.SentimentScore for row in sentiment_scores_outer_after_next.collect()]\n",
    "\n",
    "    #Differences between current year and next year\n",
    "    analyze_difference(before_prev_list, after_prev_list, str(year_val) + \" first semester\", str(next_year) + \" first semester\", year_val, alpha)\n",
    "    analyze_difference(before_next_list, after_next_list, str(year_val) + \" second semester\", str(next_year) + \" second semester\", year_val, alpha)\n",
    "\n",
    "    #Cross analysis between the two semesters of the same year\n",
    "    if len(before_prev_list) > 0 and len(before_next_list) > 0:\n",
    "        analyze_difference(before_prev_list, before_next_list, str(year_val) + \" first semester\", str(year_val) + \" second semester\", year_val, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "379d2858-b9c6-4fe9-b468-dbc6f5d9bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4348079-c8d9-4b5c-b221-f564363b9179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
